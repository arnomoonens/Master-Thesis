\documentclass[11pt, a4paper, titlepage, twoside, openright]{book}
\usepackage[american]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{bm} % To put math text in bold
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{float}
\usepackage{caption} % Change width of figure captions
\usepackage{amssymb}
\usepackage[linesnumbered, ruled]{algorithm2e}
\usepackage{titlesec}
\usepackage{hyperref} % To show urls
\usepackage[toc,page]{appendix}
\usepackage[a4paper]{geometry}
\raggedbottom
\numberwithin{equation}{section}

%Restrict width of algorithm to width of a line
\usepackage{xpatch}
\xpretocmd{\algorithm}{\hsize=\linewidth}{}{}

\setcounter{secnumdepth}{4}
\providecommand{\keywords}[1]{\textbf{\textit{Index terms---}} #1}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\ex}{\mathop{{}\mathbb{E}}}

\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

\usepackage{vub}
\usepackage{csquotes}
\usepackage[backend=biber, style=apa, uniquelist=false, maxcitenames=1,
  doi=false,
  url=false,
  isbn=false
]{biblatex}
\DeclareLanguageMapping{american}{american-apa}
\addbibresource{Mendeley.bib}

\let\cite\textcite % Use Author (Year) instead of Author, Year

\begin{document}
\frontmatter
\hypersetup{pageanchor=false}
\include{titlepage}
\hypersetup{pageanchor=true}
\setcounter{page}{1}
\chapter*{Abstract}
Deep reinforcement learning allows an agent to learn to perform a task by trial-and-error using high-dimensional input such as images. However, it is sometimes necessary to learn variations of a task, for which certain knowledge can be transferred. In this thesis, we learn multiple variations of a task in parallel using both shared knowledge and task-specific knowledge. This knowledge is then transferred to a new task. In experiments, we see that learning first in parallel on a set of source tasks significantly improves performance on a new task compared to not learning on source tasks or only using one. We also show that it is beneficial to start learning on a new task using task-specific knowledge of a source task.

\chapter*{Acknowledgments}
I would like to thank my promotor Prof. Dr. Peter Vrancx for always giving useful feedback and helping me when I was stuck. This thesis would not have been possible without his expertise and the inspiration he offered.
I would also like to thank my friends and family for always supporting me in this and all other endeavors.

%\keywords{reinforcement learning, knowledge transfer}

\tableofcontents
\listoffigures
\listofalgorithms
\listoftables

\mainmatter
\include{introduction}
\include{ann}
\include{reinforcementlearning}
\include{deeplearning}
\include{deeprl}
\include{transferlearning}
\include{proposed}
\include{expsetup}
\include{conclusion}
\include{appendices}

\backmatter
\printbibliography
\end{document}
